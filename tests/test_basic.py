"""
–°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö ML –º–æ–¥–µ–ª–µ–π —Å –ø–æ–º–æ—â—å—é Trust-ADE Protocol
"""

import numpy as np
from sklearn.datasets import make_classification
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score, classification_report
import sys
import os

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –ø—Ä–æ–µ–∫—Ç—É
project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.insert(0, project_root)

from models.sklearn_wrapper import SklearnWrapper
from trust_ade.trust_ade import TrustADE


def compare_models():
    """–°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –ø–æ Trust-ADE –º–µ—Ç—Ä–∏–∫–∞–º"""
    print("=" * 70)
    print("üî¨ –°–†–ê–í–ù–ï–ù–ò–ï –ú–û–î–ï–õ–ï–ô ML –° –ü–û–ú–û–©–¨–Æ TRUST-ADE")
    print("=" * 70)

    # –°–æ–∑–¥–∞–Ω–∏–µ —Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞
    print("\nüìä –°–æ–∑–¥–∞–Ω–∏–µ —Ç–µ—Å—Ç–æ–≤–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞...")
    X, y = make_classification(
        n_samples=1500,
        n_features=20,
        n_informative=15,
        n_redundant=5,
        n_clusters_per_class=2,
        class_sep=1.0,
        random_state=42
    )

    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.3, random_state=42, stratify=y
    )

    print(f"‚úÖ –û–±—É—á–∞—é—â–∞—è –≤—ã–±–æ—Ä–∫–∞: {X_train.shape}")
    print(f"‚úÖ –¢–µ—Å—Ç–æ–≤–∞—è –≤—ã–±–æ—Ä–∫–∞: {X_test.shape}")

    # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
    models = {
        'Random Forest': RandomForestClassifier(
            n_estimators=50,
            max_depth=8,
            random_state=42
        ),
        'Gradient Boosting': GradientBoostingClassifier(
            n_estimators=50,
            max_depth=6,
            random_state=42
        ),
        'Logistic Regression': LogisticRegression(
            random_state=42,
            max_iter=1000
        ),
        'SVM': SVC(
            kernel='rbf',
            probability=True,
            random_state=42
        )
    }

    results = {}
    trust_scores = {}

    print(f"\nü§ñ –û–±—É—á–µ–Ω–∏–µ –∏ –æ—Ü–µ–Ω–∫–∞ {len(models)} –º–æ–¥–µ–ª–µ–π...")
    print("-" * 70)

    for name, model in models.items():
        print(f"\nüìà –ú–æ–¥–µ–ª—å: {name}")

        try:
            # –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
            print("  üîÑ –û–±—É—á–µ–Ω–∏–µ...")
            model.fit(X_train, y_train)

            # –û—Ü–µ–Ω–∫–∞ —Ç–æ—á–Ω–æ—Å—Ç–∏
            train_acc = model.score(X_train, y_train)
            test_acc = model.score(X_test, y_test)

            print(f"  ‚úÖ –¢–æ—á–Ω–æ—Å—Ç—å –Ω–∞ –æ–±—É—á–µ–Ω–∏–∏: {train_acc:.3f}")
            print(f"  ‚úÖ –¢–æ—á–Ω–æ—Å—Ç—å –Ω–∞ —Ç–µ—Å—Ç–µ: {test_acc:.3f}")

            # –°–æ–∑–¥–∞–Ω–∏–µ wrapper
            wrapped_model = SklearnWrapper(model)

            # Trust-ADE –æ—Ü–µ–Ω–∫–∞
            print("  üîç –û—Ü–µ–Ω–∫–∞ Trust-ADE...")
            trust_evaluator = TrustADE(
                model=wrapped_model,
                domain='general',
                training_data=X_train
            )

            trust_result = trust_evaluator.evaluate(
                X_test=X_test,
                y_test=y_test,
                verbose=False
            )

            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            results[name] = {
                'train_accuracy': train_acc,
                'test_accuracy': test_acc,
                'trust_score': trust_result['trust_score'],
                'trust_level': trust_result['trust_level'],
                'explainability': trust_result['explainability_score'],
                'robustness': trust_result['robustness_index'],
                'bias_shift': trust_result['bias_shift_index'],
                'concept_drift': trust_result['concept_drift_rate']
            }

            trust_scores[name] = trust_result['trust_score']

            print(f"  üéØ Trust Score: {trust_result['trust_score']:.3f}")
            print(f"  üìä –£—Ä–æ–≤–µ–Ω—å –¥–æ–≤–µ—Ä–∏—è: {trust_result['trust_level']}")

        except Exception as e:
            print(f"  ‚ùå –û—à–∏–±–∫–∞ –¥–ª—è {name}: {str(e)}")
            continue

    # –ê–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    print("\n" + "=" * 70)
    print("üìä –°–†–ê–í–ù–ò–¢–ï–õ–¨–ù–´–ô –ê–ù–ê–õ–ò–ó –†–ï–ó–£–õ–¨–¢–ê–¢–û–í")
    print("=" * 70)

    if not results:
        print("‚ùå –ù–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞")
        return

    # –¢–∞–±–ª–∏—Ü–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    print(f"\n{'–ú–æ–¥–µ–ª—å':<20} {'–¢–æ—á–Ω–æ—Å—Ç—å':<10} {'Trust':<8} {'–£—Ä–æ–≤–µ–Ω—å –¥–æ–≤–µ—Ä–∏—è':<20}")
    print("-" * 65)

    for name, result in results.items():
        print(f"{name:<20} {result['test_accuracy']:<10.3f} "
              f"{result['trust_score']:<8.3f} {result['trust_level']:<20}")

    # –î–µ—Ç–∞–ª—å–Ω–∞—è —Ä–∞–∑–±–∏–≤–∫–∞ –ø–æ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞–º
    print(f"\n{'–ú–æ–¥–µ–ª—å':<20} {'–û–±—ä—è—Å–Ω.':<8} {'–£—Å—Ç–æ–π—á.':<8} {'–°–º–µ—â.':<8} {'–î—Ä–µ–π—Ñ':<8}")
    print("-" * 60)

    for name, result in results.items():
        print(f"{name:<20} {result['explainability']:<8.3f} "
              f"{result['robustness']:<8.3f} {result['bias_shift']:<8.3f} "
              f"{result['concept_drift']:<8.3f}")

    # –†–µ–π—Ç–∏–Ω–≥ –º–æ–¥–µ–ª–µ–π
    print(f"\nüèÜ –†–ï–ô–¢–ò–ù–ì –ü–û TRUST SCORE:")
    sorted_models = sorted(trust_scores.items(), key=lambda x: x[1], reverse=True)

    for i, (name, score) in enumerate(sorted_models, 1):
        medal = "ü•á" if i == 1 else "ü•à" if i == 2 else "ü•â" if i == 3 else f"{i}."
        print(f"  {medal} {name}: {score:.3f}")

    # –í—ã–≤–æ–¥—ã –∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
    print(f"\nüí° –í–´–í–û–î–´ –ò –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò:")

    best_model = sorted_models[0][0]
    best_score = sorted_models[1]

    print(f"  ‚Ä¢ –õ—É—á—à–∞—è –º–æ–¥–µ–ª—å –ø–æ Trust-ADE: {best_model} ({best_score:.3f})")

    # –ê–Ω–∞–ª–∏–∑ –ø–æ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞–º
    best_explainability = max(results.items(), key=lambda x: x[1]['explainability'])
    best_robustness = max(results.items(), key=lambda x: x[1]['robustness'])

    print(f"  ‚Ä¢ –õ—É—á—à–∞—è –æ–±—ä—è—Å–Ω–∏–º–æ—Å—Ç—å: {best_explainability[0]} ({best_explainability[1]['explainability']:.3f})")
    print(f"  ‚Ä¢ –õ—É—á—à–∞—è —É—Å—Ç–æ–π—á–∏–≤–æ—Å—Ç—å: {best_robustness[0]} ({best_robustness[1]['robustness']:.3f})")

    # –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è
    low_trust_models = [name for name, score in trust_scores.items() if score < 0.5]
    if low_trust_models:
        print(f"  ‚ö†Ô∏è  –ú–æ–¥–µ–ª–∏ —Å –Ω–∏–∑–∫–∏–º –¥–æ–≤–µ—Ä–∏–µ–º: {', '.join(low_trust_models)}")

    return results


def analyze_domain_sensitivity():
    """–ê–Ω–∞–ª–∏–∑ —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∫ —Ä–∞–∑–ª–∏—á–Ω—ã–º –¥–æ–º–µ–Ω–∞–º"""
    print("\n" + "=" * 70)
    print("üè∑Ô∏è –ê–ù–ê–õ–ò–ó –ß–£–í–°–¢–í–ò–¢–ï–õ–¨–ù–û–°–¢–ò –ö –î–û–ú–ï–ù–ê–ú")
    print("=" * 70)

    # –ü—Ä–æ—Å—Ç–æ–π –¥–∞—Ç–∞—Å–µ—Ç –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
    X, y = make_classification(n_samples=500, n_features=10, random_state=42)
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

    # –û–¥–Ω–∞ –º–æ–¥–µ–ª—å - —Ä–∞–∑–Ω—ã–µ –¥–æ–º–µ–Ω—ã
    model = RandomForestClassifier(n_estimators=30, random_state=42)
    model.fit(X_train, y_train)
    wrapped_model = SklearnWrapper(model)

    domains = ['general', 'medical', 'finance', 'criminal_justice']
    domain_results = {}

    print(f"\nüîç –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ –≤ {len(domains)} –¥–æ–º–µ–Ω–∞—Ö...")

    for domain in domains:
        print(f"\nüìã –î–æ–º–µ–Ω: {domain}")

        trust_evaluator = TrustADE(
            model=wrapped_model,
            domain=domain,
            training_data=X_train
        )

        result = trust_evaluator.evaluate(X_test, y_test, verbose=False)
        domain_results[domain] = result

        print(f"  üéØ Trust Score: {result['trust_score']:.3f}")

        weights = result['weights_used']
        print(f"  ‚öñÔ∏è –í–µ—Å–∞: E={weights['w_E']:.2f}, R={weights['w_R']:.2f}, F={weights['w_F']:.2f}")

    # –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –¥–æ–º–µ–Ω–æ–≤
    print(f"\nüìä –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –¥–æ–º–µ–Ω–æ–≤:")
    print(f"{'–î–æ–º–µ–Ω':<20} {'Trust Score':<12} {'–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç'}")
    print("-" * 50)

    domain_priorities = {
        'general': '–°–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–π',
        'medical': '–û–±—ä—è—Å–Ω–∏–º–æ—Å—Ç—å',
        'finance': '–£—Å—Ç–æ–π—á–∏–≤–æ—Å—Ç—å',
        'criminal_justice': '–°–ø—Ä–∞–≤–µ–¥–ª–∏–≤–æ—Å—Ç—å'
    }

    for domain, result in domain_results.items():
        priority = domain_priorities.get(domain, '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ')
        print(f"{domain:<20} {result['trust_score']:<12.3f} {priority}")

    return domain_results


if __name__ == "__main__":
    print("üöÄ –ó–∞–ø—É—Å–∫ —Å—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ –º–æ–¥–µ–ª–µ–π")

    # –û—Å–Ω–æ–≤–Ω–æ–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π
    model_results = compare_models()

    # –ê–Ω–∞–ª–∏–∑ –¥–æ–º–µ–Ω–Ω–æ–π —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
    domain_results = analyze_domain_sensitivity()

    print(f"\nüéâ –°—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω!")
    print(f"üìä –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ –º–æ–¥–µ–ª–µ–π: {len(model_results) if model_results else 0}")
    print(f"üè∑Ô∏è –ü—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–æ –¥–æ–º–µ–Ω–æ–≤: {len(domain_results) if domain_results else 0}")
