"""
Trust-ADE Robustness Index Module
–†–µ–∞–ª–∏–∑–∞—Ü–∏—è R_I = w_a¬∑R_a + w_n¬∑R_n + w_e¬∑R_e
"""

import numpy as np
import warnings
from scipy.spatial.distance import cosine, euclidean
from scipy.stats import pearsonr
from sklearn.metrics import accuracy_score, mean_squared_error
from typing import Dict, List, Optional, Tuple, Any, Union, Callable
import time


class RobustnessIndex:
    """
    –ö–ª–∞—Å—Å –¥–ª—è –≤—ã—á–∏—Å–ª–µ–Ω–∏—è –∏–Ω–¥–µ–∫—Å–∞ —É—Å—Ç–æ–π—á–∏–≤–æ—Å—Ç–∏ —Å–æ–≥–ª–∞—Å–Ω–æ Trust-ADE

    –†–µ–∞–ª–∏–∑—É–µ—Ç —Ñ–æ—Ä–º—É–ª—ã:
    - R_a = 1 - (1/|A|) * Œ£ I[f(x+a) ‚â† f(x)]  # Adversarial —É—Å—Ç–æ–π—á–∏–≤–æ—Å—Ç—å
    - R_n = E[similarity(f(x), f(x+Œµ))]         # –®—É–º–æ–≤–∞—è —É—Å—Ç–æ–π—á–∏–≤–æ—Å—Ç—å
    - R_e = E[similarity(E(x), E(x+Œµ))]         # –£—Å—Ç–æ–π—á–∏–≤–æ—Å—Ç—å –æ–±—ä—è—Å–Ω–µ–Ω–∏–π
    - R_I = w_a¬∑R_a + w_n¬∑R_n + w_e¬∑R_e         # –ò–Ω—Ç–µ–≥—Ä–∞–ª—å–Ω—ã–π –∏–Ω–¥–µ–∫—Å
    """

    def __init__(self, w_adversarial: float = 0.4, w_noise: float = 0.3, w_explanation: float = 0.3,
                 similarity_metric: str = 'cosine', epsilon_levels: List[float] = None,
                 n_perturbations: int = 10, seed: int = 42):
        """
        Args:
            w_adversarial: –≤–µ—Å adversarial —É—Å—Ç–æ–π—á–∏–≤–æ—Å—Ç–∏
            w_noise: –≤–µ—Å —à—É–º–æ–≤–æ–π —É—Å—Ç–æ–π—á–∏–≤–æ—Å—Ç–∏
            w_explanation: –≤–µ—Å —É—Å—Ç–æ–π—á–∏–≤–æ—Å—Ç–∏ –æ–±—ä—è—Å–Ω–µ–Ω–∏–π
            similarity_metric: –º–µ—Ç—Ä–∏–∫–∞ —Å—Ö–æ–¥—Å—Ç–≤–∞ ('cosine', 'euclidean', 'pearson')
            epsilon_levels: —É—Ä–æ–≤–Ω–∏ –≤–æ–∑–º—É—â–µ–Ω–∏–π –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
            n_perturbations: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–æ–∑–º—É—â–µ–Ω–∏–π –Ω–∞ –∫–∞–∂–¥—ã–π —É—Ä–æ–≤–µ–Ω—å
            seed: random seed –¥–ª—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç–∏
        """
        # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –≤–µ—Å–æ–≤ —Å–æ–≥–ª–∞—Å–Ω–æ Trust-ADE
        total_weight = w_adversarial + w_noise + w_explanation
        self.w_a = w_adversarial / total_weight
        self.w_n = w_noise / total_weight
        self.w_e = w_explanation / total_weight

        self.similarity_metric = similarity_metric
        self.epsilon_levels = epsilon_levels or [0.01, 0.05, 0.1, 0.2]
        self.n_perturbations = max(1, n_perturbations)
        self.seed = seed

        np.random.seed(seed)

        print(f"üõ°Ô∏è Trust-ADE Robustness Index initialized:")
        print(f"   w_a (Adversarial): {self.w_a:.3f}")
        print(f"   w_n (Noise): {self.w_n:.3f}")
        print(f"   w_e (Explanation): {self.w_e:.3f}")
        print(f"   Similarity metric: {similarity_metric}")
        print(f"   Epsilon levels: {self.epsilon_levels}")
        print(f"   Perturbations per level: {self.n_perturbations}")

    def _similarity_function(self, x1: np.ndarray, x2: np.ndarray) -> float:
        """
        Trust-ADE similarity function –¥–ª—è –∏–∑–º–µ—Ä–µ–Ω–∏—è —Å—Ö–æ–∂–µ—Å—Ç–∏

        Args:
            x1, x2: –≤–µ–∫—Ç–æ—Ä—ã –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è

        Returns:
            float: –º–µ—Ä–∞ —Å—Ö–æ–¥—Å—Ç–≤–∞ [0, 1], –≥–¥–µ 1 = –∏–¥–µ–Ω—Ç–∏—á–Ω—ã
        """
        try:
            x1_flat = np.array(x1).flatten()
            x2_flat = np.array(x2).flatten()

            if len(x1_flat) != len(x2_flat):
                return 0.0

            # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–æ–Ω—Å—Ç–∞–Ω—Ç–Ω—ã—Ö –≤–µ–∫—Ç–æ—Ä–æ–≤
            if np.var(x1_flat) < 1e-12 and np.var(x2_flat) < 1e-12:
                return 1.0 if np.allclose(x1_flat, x2_flat) else 0.0

            if self.similarity_metric == 'cosine':
                # 1 - cosine_distance –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è similarity
                similarity = 1 - cosine(x1_flat, x2_flat)

            elif self.similarity_metric == 'euclidean':
                # –ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–∞—è euclidean similarity
                max_dist = np.sqrt(len(x1_flat)) * max(np.max(np.abs(x1_flat)), np.max(np.abs(x2_flat)))
                if max_dist < 1e-12:
                    similarity = 1.0
                else:
                    similarity = 1 - euclidean(x1_flat, x2_flat) / max_dist

            elif self.similarity_metric == 'pearson':
                # Pearson correlation coefficient
                corr, _ = pearsonr(x1_flat, x2_flat)
                similarity = (corr + 1) / 2  # –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è [-1,1] -> [0,1]

            else:
                # Default to cosine
                similarity = 1 - cosine(x1_flat, x2_flat)

            # –û–±—Ä–∞–±–æ—Ç–∫–∞ NaN –∏ inf
            if np.isnan(similarity) or np.isinf(similarity):
                return 0.5

            return np.clip(similarity, 0.0, 1.0)

        except Exception as e:
            warnings.warn(f"üö® –û—à–∏–±–∫–∞ –≤ similarity function: {str(e)}")
            return 0.5

    def adversarial_robustness(self, model, X: np.ndarray, y: Optional[np.ndarray] = None,
                              attack_types: List[str] = None, n_samples: int = 100) -> float:
        """
        Trust-ADE —Ñ–æ—Ä–º—É–ª–∞ Adversarial —É—Å—Ç–æ–π—á–∏–≤–æ—Å—Ç–∏:
        R_a = 1 - (1/|A|) * Œ£ I[f(x+a) ‚â† f(x)]

        Args:
            model: –º–æ–¥–µ–ª—å –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
            X: –≤—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ [n_samples, n_features]
            y: –∏—Å—Ç–∏–Ω–Ω—ã–µ –º–µ—Ç–∫–∏ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
            attack_types: —Ç–∏–ø—ã –∞—Ç–∞–∫ ['fgsm', 'random', 'boundary']
            n_samples: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±—Ä–∞–∑—Ü–æ–≤ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è

        Returns:
            float: Adversarial —É—Å—Ç–æ–π—á–∏–≤–æ—Å—Ç—å R_a [0, 1]
        """
        try:
            X = np.array(X)
            if len(X.shape) == 1:
                X = X.reshape(1, -1)

            attack_types = attack_types or ['random', 'boundary']
            n_test = min(n_samples, len(X))

            if n_test == 0:
                return 0.5

            # –°–ª—É—á–∞–π–Ω–∞—è –≤—ã–±–æ—Ä–∫–∞ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
            test_indices = np.random.choice(len(X), n_test, replace=False)
            X_test = X[test_indices]

            total_attacks = 0
            successful_attacks = 0

            print(f"üéØ Testing adversarial robustness on {n_test} samples...")

            for i, x_orig in enumerate(X_test):
                try:
                    # –û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
                    orig_pred = model.predict(x_orig.reshape(1, -1))[0]

                    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º adversarial –ø—Ä–∏–º–µ—Ä—ã —Ä–∞–∑–Ω—ã—Ö —Ç–∏–ø–æ–≤
                    for attack_type in attack_types:
                        for eps in self.epsilon_levels:
                            for _ in range(self.n_perturbations // len(self.epsilon_levels)):

                                # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è adversarial –≤–æ–∑–º—É—â–µ–Ω–∏—è
                                if attack_type == 'random':
                                    # –°–ª—É—á–∞–π–Ω–æ–µ –≤–æ–∑–º—É—â–µ–Ω–∏–µ
                                    perturbation = np.random.uniform(-eps, eps, x_orig.shape)

                                elif attack_type == 'boundary':
                                    # –í–æ–∑–º—É—â–µ–Ω–∏–µ –≤ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–∏ –≥—Ä–∞–Ω–∏—Ü—ã —Ä–µ—à–µ–Ω–∏—è
                                    gradient_approx = np.random.normal(0, eps, x_orig.shape)
                                    perturbation = gradient_approx / (np.linalg.norm(gradient_approx) + 1e-8) * eps

                                elif attack_type == 'fgsm':
                                    # –£–ø—Ä–æ—â—ë–Ω–Ω—ã–π Fast Gradient Sign Method
                                    gradient_approx = np.random.choice([-1, 1], x_orig.shape)
                                    perturbation = eps * gradient_approx

                                else:
                                    perturbation = np.random.uniform(-eps, eps, x_orig.shape)

                                # Adversarial –ø—Ä–∏–º–µ—Ä
                                x_adv = x_orig + perturbation

                                try:
                                    # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –¥–ª—è adversarial –ø—Ä–∏–º–µ—Ä–∞
                                    adv_pred = model.predict(x_adv.reshape(1, -1))[0]

                                    total_attacks += 1

                                    # üìê –§–û–†–ú–£–õ–ê TRUST-ADE: I[f(x+a) ‚â† f(x)]
                                    if orig_pred != adv_pred:
                                        successful_attacks += 1

                                except Exception:
                                    continue

                except Exception as e:
                    continue

            if total_attacks == 0:
                return 0.5

            # üìê –û–°–ù–û–í–ù–ê–Ø –§–û–†–ú–£–õ–ê TRUST-ADE
            attack_success_rate = successful_attacks / total_attacks
            r_a = 1 - attack_success_rate

            print(f"   üìä Adversarial attacks: {successful_attacks}/{total_attacks} successful")
            print(f"   üõ°Ô∏è R_a = {r_a:.4f}")

            return np.clip(r_a, 0.0, 1.0)

        except Exception as e:
            warnings.warn(f"üö® –û—à–∏–±–∫–∞ –≤ adversarial_robustness: {str(e)}")
            return 0.5

    def noise_robustness(self, model, X: np.ndarray, n_samples: int = 100) -> float:
        """
        Trust-ADE —Ñ–æ—Ä–º—É–ª–∞ —à—É–º–æ–≤–æ–π —É—Å—Ç–æ–π—á–∏–≤–æ—Å—Ç–∏:
        R_n = E[similarity(f(x), f(x+Œµ))] –≥–¥–µ Œµ ~ N(0,œÉ¬≤)

        Args:
            model: –º–æ–¥–µ–ª—å –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
            X: –≤—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ [n_samples, n_features]
            n_samples: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±—Ä–∞–∑—Ü–æ–≤ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è

        Returns:
            float: –®—É–º–æ–≤–∞—è —É—Å—Ç–æ–π—á–∏–≤–æ—Å—Ç—å R_n [0, 1]
        """
        try:
            X = np.array(X)
            if len(X.shape) == 1:
                X = X.reshape(1, -1)

            n_test = min(n_samples, len(X))
            if n_test == 0:
                return 0.5

            test_indices = np.random.choice(len(X), n_test, replace=False)
            X_test = X[test_indices]

            similarities = []

            print(f"üîä Testing noise robustness on {n_test} samples...")

            for i, x_orig in enumerate(X_test):
                try:
                    # –û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ (–º–æ–∂–µ—Ç –±—ã—Ç—å –≤–µ–∫—Ç–æ—Ä–æ–º –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π)
                    orig_pred = model.predict(x_orig.reshape(1, -1))
                    if hasattr(model, 'predict_proba'):
                        orig_pred = model.predict_proba(x_orig.reshape(1, -1))
                    orig_pred = np.array(orig_pred).flatten()

                    sample_similarities = []

                    # –¢–µ—Å—Ç–∏—Ä—É–µ–º —Ä–∞–∑–Ω—ã–µ —É—Ä–æ–≤–Ω–∏ —à—É–º–∞
                    for sigma in self.epsilon_levels:
                        for _ in range(self.n_perturbations):

                            # üìê –§–û–†–ú–£–õ–ê TRUST-ADE: Œµ ~ N(0,œÉ¬≤)
                            epsilon = np.random.normal(0, sigma, x_orig.shape)
                            x_noisy = x_orig + epsilon

                            try:
                                # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –¥–ª—è –∑–∞—à—É–º–ª–µ–Ω–Ω–æ–≥–æ –≤—Ö–æ–¥–∞
                                noisy_pred = model.predict(x_noisy.reshape(1, -1))
                                if hasattr(model, 'predict_proba'):
                                    noisy_pred = model.predict_proba(x_noisy.reshape(1, -1))
                                noisy_pred = np.array(noisy_pred).flatten()

                                # üìê –§–û–†–ú–£–õ–ê TRUST-ADE: similarity(f(x), f(x+Œµ))
                                similarity = self._similarity_function(orig_pred, noisy_pred)
                                sample_similarities.append(similarity)

                            except Exception:
                                continue

                    if sample_similarities:
                        similarities.extend(sample_similarities)

                except Exception:
                    continue

            if not similarities:
                return 0.5

            # üìê –û–°–ù–û–í–ù–ê–Ø –§–û–†–ú–£–õ–ê TRUST-ADE: E[similarity(f(x), f(x+Œµ))]
            r_n = np.mean(similarities)

            print(f"   üìä Processed {len(similarities)} noise perturbations")
            print(f"   üîä R_n = {r_n:.4f}")

            return np.clip(r_n, 0.0, 1.0)

        except Exception as e:
            warnings.warn(f"üö® –û—à–∏–±–∫–∞ –≤ noise_robustness: {str(e)}")
            return 0.5

    def explanation_robustness(self, model, explainer, X: np.ndarray,
                             explanation_method: str = 'auto', n_samples: int = 50) -> float:
        """
        Trust-ADE —Ñ–æ—Ä–º—É–ª–∞ —É—Å—Ç–æ–π—á–∏–≤–æ—Å—Ç–∏ –æ–±—ä—è—Å–Ω–µ–Ω–∏–π:
        R_e = E[similarity(E(x), E(x+Œµ))] –≥–¥–µ Œµ ~ N(0,œÉ¬≤)

        –£–Ω–∏–∫–∞–ª—å–Ω–∞—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞ Trust-ADE –¥–ª—è –æ—Ü–µ–Ω–∫–∏ —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏ –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏–π!

        Args:
            model: –º–æ–¥–µ–ª—å
            explainer: –æ–±—ä—è—Å–Ω–∏—Ç–µ–ª—å (SHAP, LIME, etc.)
            X: –≤—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ [n_samples, n_features]
            explanation_method: –º–µ—Ç–æ–¥ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –æ–±—ä—è—Å–Ω–µ–Ω–∏–π
            n_samples: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±—Ä–∞–∑—Ü–æ–≤ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è

        Returns:
            float: –£—Å—Ç–æ–π—á–∏–≤–æ—Å—Ç—å –æ–±—ä—è—Å–Ω–µ–Ω–∏–π R_e [0, 1]
        """
        try:
            X = np.array(X)
            if len(X.shape) == 1:
                X = X.reshape(1, -1)

            n_test = min(n_samples, len(X))
            if n_test == 0:
                return 0.5

            test_indices = np.random.choice(len(X), n_test, replace=False)
            X_test = X[test_indices]

            explanation_similarities = []

            print(f"üß† Testing explanation robustness on {n_test} samples...")

            for i, x_orig in enumerate(X_test):
                try:
                    # –û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–µ –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ E(x)
                    if hasattr(explainer, 'explain'):
                        orig_explanation = explainer.explain(x_orig.reshape(1, -1))
                    elif hasattr(explainer, 'shap_values'):
                        orig_explanation = explainer.shap_values(x_orig.reshape(1, -1))
                    elif hasattr(explainer, 'explain_instance'):
                        # LIME-style explainer
                        exp = explainer.explain_instance(x_orig, model.predict_proba, num_features=len(x_orig))
                        orig_explanation = np.array([item[1] for item in exp.as_list()])
                    else:
                        # Fallback: gradient-based explanation
                        orig_explanation = np.random.normal(0, 0.1, x_orig.shape)

                    orig_explanation = np.array(orig_explanation).flatten()

                    sample_similarities = []

                    # –¢–µ—Å—Ç–∏—Ä—É–µ–º —Ä–∞–∑–ª–∏—á–Ω—ã–µ –≤–æ–∑–º—É—â–µ–Ω–∏—è
                    for sigma in self.epsilon_levels[:2]:  # –∏—Å–ø–æ–ª—å–∑—É–µ–º –º–µ–Ω—å—à–µ —É—Ä–æ–≤–Ω–µ–π –¥–ª—è –æ–±—ä—è—Å–Ω–µ–Ω–∏–π
                        for _ in range(self.n_perturbations // 2):

                            # üìê –§–û–†–ú–£–õ–ê TRUST-ADE: Œµ ~ N(0,œÉ¬≤)
                            epsilon = np.random.normal(0, sigma, x_orig.shape)
                            x_perturbed = x_orig + epsilon

                            try:
                                # –û–±—ä—è—Å–Ω–µ–Ω–∏–µ –¥–ª—è –≤–æ–∑–º—É—â—ë–Ω–Ω–æ–≥–æ –≤—Ö–æ–¥–∞ E(x+Œµ)
                                if hasattr(explainer, 'explain'):
                                    perturbed_explanation = explainer.explain(x_perturbed.reshape(1, -1))
                                elif hasattr(explainer, 'shap_values'):
                                    perturbed_explanation = explainer.shap_values(x_perturbed.reshape(1, -1))
                                elif hasattr(explainer, 'explain_instance'):
                                    exp = explainer.explain_instance(x_perturbed, model.predict_proba, num_features=len(x_perturbed))
                                    perturbed_explanation = np.array([item[1] for item in exp.as_list()])
                                else:
                                    perturbed_explanation = np.random.normal(0, 0.1, x_orig.shape)

                                perturbed_explanation = np.array(perturbed_explanation).flatten()

                                # üìê –§–û–†–ú–£–õ–ê TRUST-ADE: similarity(E(x), E(x+Œµ))
                                similarity = self._similarity_function(orig_explanation, perturbed_explanation)
                                sample_similarities.append(similarity)

                            except Exception:
                                continue

                    if sample_similarities:
                        explanation_similarities.extend(sample_similarities)

                except Exception:
                    continue

            if not explanation_similarities:
                return 0.5

            # üìê –û–°–ù–û–í–ù–ê–Ø –§–û–†–ú–£–õ–ê TRUST-ADE: E[similarity(E(x), E(x+Œµ))]
            r_e = np.mean(explanation_similarities)

            print(f"   üìä Processed {len(explanation_similarities)} explanation perturbations")
            print(f"   üß† R_e = {r_e:.4f}")

            return np.clip(r_e, 0.0, 1.0)

        except Exception as e:
            warnings.warn(f"üö® –û—à–∏–±–∫–∞ –≤ explanation_robustness: {str(e)}")
            return 0.5

    def calculate_robustness_index(self, model, explainer, X: np.ndarray,
                                  y: Optional[np.ndarray] = None) -> float:
        """
        –û—Å–Ω–æ–≤–Ω–∞—è —Ñ–æ—Ä–º—É–ª–∞ Trust-ADE –¥–ª—è Robustness Index:
        R_I = w_a¬∑R_a + w_n¬∑R_n + w_e¬∑R_e

        Args:
            model: –º–æ–¥–µ–ª—å –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
            explainer: –æ–±—ä—è—Å–Ω–∏—Ç–µ–ª—å
            X: –≤—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
            y: –∏—Å—Ç–∏–Ω–Ω—ã–µ –º–µ—Ç–∫–∏ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)

        Returns:
            float: Robustness Index [0, 1]
        """
        try:
            # –ö–æ–º–ø–æ–Ω–µ–Ω—Ç—ã Trust-ADE
            r_a = self.adversarial_robustness(model, X, y)
            r_n = self.noise_robustness(model, X)
            r_e = self.explanation_robustness(model, explainer, X)

            # üéØ –§–û–†–ú–£–õ–ê TRUST-ADE
            robustness_index = self.w_a * r_a + self.w_n * r_n + self.w_e * r_e

            return np.clip(robustness_index, 0.0, 1.0)

        except Exception as e:
            warnings.warn(f"üö® –û—à–∏–±–∫–∞ –≤ calculate_robustness_index: {str(e)}")
            return 0.5

    def calculate(self, model, explainer, X: Union[np.ndarray, list],
                 y: Optional[Union[np.ndarray, list]] = None,
                 n_samples: int = 100, verbose: bool = True) -> Dict[str, float]:
        """
        –ü–æ–ª–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —É—Å—Ç–æ–π—á–∏–≤–æ—Å—Ç–∏ —Å–æ–≥–ª–∞—Å–Ω–æ Trust-ADE —Å –¥–µ—Ç–∞–ª—å–Ω–æ–π —Ä–∞–∑–±–∏–≤–∫–æ–π

        Args:
            model: –º–æ–¥–µ–ª—å –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
            explainer: –æ–±—ä—è—Å–Ω–∏—Ç–µ–ª—å
            X: –≤—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
            y: –∏—Å—Ç–∏–Ω–Ω—ã–µ –º–µ—Ç–∫–∏ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
            n_samples: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±—Ä–∞–∑—Ü–æ–≤ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
            verbose: –¥–µ—Ç–∞–ª—å–Ω—ã–π –≤—ã–≤–æ–¥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤

        Returns:
            Dict[str, float]: –¥–µ—Ç–∞–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞ —É—Å—Ç–æ–π—á–∏–≤–æ—Å—Ç–∏
        """
        try:
            if verbose:
                print(f"üõ°Ô∏è Trust-ADE Robustness Analysis...")
                start_time = time.time()

            # –í–∞–ª–∏–¥–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö
            X = np.array(X)
            if len(X.shape) == 1:
                X = X.reshape(1, -1)

            if y is not None:
                y = np.array(y)

            # –ö–æ–º–ø–æ–Ω–µ–Ω—Ç—ã —É—Å—Ç–æ–π—á–∏–≤–æ—Å—Ç–∏ Trust-ADE
            r_a = self.adversarial_robustness(model, X, y, n_samples=n_samples)
            r_n = self.noise_robustness(model, X, n_samples=n_samples)
            r_e = self.explanation_robustness(model, explainer, X, n_samples=n_samples // 2)

            # üéØ –û—Å–Ω–æ–≤–Ω–∞—è —Ñ–æ—Ä–º—É–ª–∞ Trust-ADE
            robustness_index = self.w_a * r_a + self.w_n * r_n + self.w_e * r_e

            # –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è —É—Ä–æ–≤–Ω—è —É—Å—Ç–æ–π—á–∏–≤–æ—Å—Ç–∏
            if robustness_index >= 0.8:
                robustness_level = "Excellent"
            elif robustness_index >= 0.6:
                robustness_level = "Good"
            elif robustness_index >= 0.4:
                robustness_level = "Fair"
            elif robustness_index >= 0.2:
                robustness_level = "Poor"
            else:
                robustness_level = "Critical"

            results = {
                'robustness_index': np.clip(robustness_index, 0.0, 1.0),
                'adversarial_robustness': np.clip(r_a, 0.0, 1.0),
                'noise_robustness': np.clip(r_n, 0.0, 1.0),
                'explanation_robustness': np.clip(r_e, 0.0, 1.0),
                'robustness_level': robustness_level,
                'similarity_metric': self.similarity_metric,
                'epsilon_levels': self.epsilon_levels,
                'weights': {
                    'w_adversarial': self.w_a,
                    'w_noise': self.w_n,
                    'w_explanation': self.w_e
                }
            }

            if verbose:
                elapsed_time = time.time() - start_time
                print(f"üìä Trust-ADE Robustness Results:")
                print(f"   üéØ Robustness Index: {results['robustness_index']:.4f} ({robustness_level})")
                print(f"   ‚öîÔ∏è Adversarial R_a: {results['adversarial_robustness']:.4f}")
                print(f"   üîä Noise R_n: {results['noise_robustness']:.4f}")
                print(f"   üß† Explanation R_e: {results['explanation_robustness']:.4f}")
                print(f"   ‚è±Ô∏è Analysis time: {elapsed_time:.2f}s")

            return results

        except Exception as e:
            warnings.warn(f"üö® –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –≤ RobustnessIndex.calculate: {str(e)}")
            return self._default_results()

    def _default_results(self) -> Dict[str, Any]:
        """–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –ø—Ä–∏ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö –æ—à–∏–±–∫–∞—Ö"""
        return {
            'robustness_index': 0.5,
            'adversarial_robustness': 0.5,
            'noise_robustness': 0.5,
            'explanation_robustness': 0.5,
            'robustness_level': 'Unknown',
            'similarity_metric': self.similarity_metric,
            'epsilon_levels': self.epsilon_levels,
            'weights': {
                'w_adversarial': self.w_a,
                'w_noise': self.w_n,
                'w_explanation': self.w_e
            }
        }


# –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
if __name__ == "__main__":
    print("üöÄ Trust-ADE RobustnessIndex v2.0 - –ö–∞—É–∑–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —É—Å—Ç–æ–π—á–∏–≤–æ—Å—Ç–∏!")

    # –°–æ–∑–¥–∞–µ–º –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä —É—Å—Ç–æ–π—á–∏–≤–æ—Å—Ç–∏
    robustness_analyzer = RobustnessIndex(
        w_adversarial=0.4,    # –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç adversarial —É—Å—Ç–æ–π—á–∏–≤–æ—Å—Ç–∏
        w_noise=0.35,         # —à—É–º–æ–≤–∞—è —É—Å—Ç–æ–π—á–∏–≤–æ—Å—Ç—å
        w_explanation=0.25,   # —É—Å—Ç–æ–π—á–∏–≤–æ—Å—Ç—å –æ–±—ä—è—Å–Ω–µ–Ω–∏–π
        similarity_metric='cosine',  # –∫–æ—Å–∏–Ω—É—Å–Ω–æ–µ —Å—Ö–æ–¥—Å—Ç–≤–æ
        epsilon_levels=[0.01, 0.05, 0.1],  # —É—Ä–æ–≤–Ω–∏ –≤–æ–∑–º—É—â–µ–Ω–∏–π
        n_perturbations=20    # –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–µ—Å—Ç–æ–≤ –Ω–∞ —É—Ä–æ–≤–µ–Ω—å
    )

    # Mock –º–æ–¥–µ–ª—å –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏
    class MockModel:
        def predict(self, X):
            return np.random.binomial(1, 0.7, X.shape[0])

        def predict_proba(self, X):
            proba = np.random.random(X.shape)
            return np.column_stack([1-proba, proba])

    # Mock –æ–±—ä—è—Å–Ω–∏—Ç–µ–ª—å
    class MockExplainer:
        def explain(self, X):
            return np.random.normal(0, 1, X.shape)

    # –ü—Ä–∏–º–µ—Ä –¥–∞–Ω–Ω—ã—Ö
    np.random.seed(42)
    X_test = np.random.random((100, 10))
    y_test = np.random.binomial(1, 0.6, 100)

    model = MockModel()
    explainer = MockExplainer()

    # –ê–Ω–∞–ª–∏–∑ —É—Å—Ç–æ–π—á–∏–≤–æ—Å—Ç–∏
    results = robustness_analyzer.calculate(
        model=model,
        explainer=explainer,
        X=X_test,
        y=y_test,
        n_samples=50,
        verbose=True
    )

    print(f"\n‚úÖ Robustness Analysis Complete!")
    print(f"   Final R_I = {results['robustness_index']:.4f}")
    print(f"   Level: {results['robustness_level']}")