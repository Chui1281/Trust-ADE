"""
Trust-ADE Bias Shift Index Module
–†–µ–∞–ª–∏–∑–∞—Ü–∏—è BS_I = ‚àö(w_dp¬∑DP_Œî¬≤ + w_eo¬∑EO_Œî¬≤ + w_cf¬∑CF_Œî¬≤)
"""

import numpy as np
import warnings
from sklearn.metrics import accuracy_score
from typing import Dict, List, Optional, Tuple, Any, Union


class BiasShiftIndex:
    """
    –ö–ª–∞—Å—Å –¥–ª—è –≤—ã—á–∏—Å–ª–µ–Ω–∏—è –∏–Ω–¥–µ–∫—Å–∞ —Å–º–µ—â–µ–Ω–∏—è –ø—Ä–µ–¥–≤–∑—è—Ç–æ—Å—Ç–∏ —Å–æ–≥–ª–∞—Å–Ω–æ Trust-ADE

    –†–µ–∞–ª–∏–∑—É–µ—Ç —Ñ–æ—Ä–º—É–ª—ã:
    - DP_Œî = |P(≈∑=1|A=0) - P(≈∑=1|A=1)|_t - |P(≈∑=1|A=0) - P(≈∑=1|A=1)|_t-Œît
    - EO_Œî = max_y |P(≈∑=1|A=0,y) - P(≈∑=1|A=1,y)|_t - max_y |P(≈∑=1|A=0,y) - P(≈∑=1|A=1,y)|_t-Œît
    - CF_Œî = |Acc(A=0) - Acc(A=1)|_t - |Acc(A=0) - Acc(A=1)|_t-Œît
    - BS_I = ‚àö(w_dp¬∑DP_Œî¬≤ + w_eo¬∑EO_Œî¬≤ + w_cf¬∑CF_Œî¬≤)
    """

    def __init__(self, protected_attributes: Optional[List[str]] = None,
                 dp_weight: float = 0.4, eo_weight: float = 0.4, cf_weight: float = 0.2,
                 min_group_size: int = 10):
        """
        Args:
            protected_attributes: —Å–ø–∏—Å–æ–∫ –∑–∞—â–∏—â—ë–Ω–Ω—ã—Ö –∞—Ç—Ä–∏–±—É—Ç–æ–≤ –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞
            dp_weight: –≤–µ—Å –¥–µ–º–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–æ–≥–æ –ø–∞—Ä–∏—Ç–µ—Ç–∞
            eo_weight: –≤–µ—Å —Ä–∞–≤–µ–Ω—Å—Ç–≤–∞ —à–∞–Ω—Å–æ–≤
            cf_weight: –≤–µ—Å –∫–∞–ª–∏–±—Ä–æ–≤–∞–Ω–Ω–æ–π —Å–ø—Ä–∞–≤–µ–¥–ª–∏–≤–æ—Å—Ç–∏
            min_group_size: –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä –≥—Ä—É–ø–ø—ã –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
        """
        self.protected_attributes = protected_attributes or []

        # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –≤–µ—Å–æ–≤
        total = dp_weight + eo_weight + cf_weight
        self.w_dp = dp_weight / total
        self.w_eo = eo_weight / total
        self.w_cf = cf_weight / total

        self.min_group_size = max(1, min_group_size)

        print(f"‚öñÔ∏è Trust-ADE Bias Shift Index initialized:")
        print(f"   w_dp (Demographic Parity): {self.w_dp:.3f}")
        print(f"   w_eo (Equalized Odds): {self.w_eo:.3f}")
        print(f"   w_cf (Calibrated Fairness): {self.w_cf:.3f}")
        print(f"   Min group size: {self.min_group_size}")

    def demographic_parity_shift(self, y_pred_current: np.ndarray,
                                 y_pred_baseline: np.ndarray,
                                 protected_attr: np.ndarray) -> float:
        """
        Trust-ADE —Ñ–æ—Ä–º—É–ª–∞ –¥–µ–º–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–æ–≥–æ –ø–∞—Ä–∏—Ç–µ—Ç–∞:
        DP_Œî = |P(≈∑=1|A=0) - P(≈∑=1|A=1)|_t - |P(≈∑=1|A=0) - P(≈∑=1|A=1)|_t-Œît

        Args:
            y_pred_current: —Ç–µ–∫—É—â–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è [0/1]
            y_pred_baseline: –±–∞–∑–æ–≤—ã–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è [0/1]
            protected_attr: –∑–Ω–∞—á–µ–Ω–∏—è –∑–∞—â–∏—â—ë–Ω–Ω–æ–≥–æ –∞—Ç—Ä–∏–±—É—Ç–∞

        Returns:
            float: –∏–∑–º–µ–Ω–µ–Ω–∏–µ –¥–µ–º–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–æ–≥–æ –ø–∞—Ä–∏—Ç–µ—Ç–∞ [0, 1]
        """
        try:
            protected_attr = np.array(protected_attr)
            y_pred_current = np.array(y_pred_current)
            y_pred_baseline = np.array(y_pred_baseline)

            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –≤–∞–ª–∏–¥–Ω–æ—Å—Ç–∏ –¥–∞–Ω–Ω—ã—Ö
            unique_groups = np.unique(protected_attr)
            if len(unique_groups) < 2:
                return 0.0  # –Ω–µ—Ç —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è –Ω–∞ –≥—Ä—É–ø–ø—ã

            # –ë–µ—Ä—ë–º –ø–µ—Ä–≤—ã–µ –¥–≤–µ –≥—Ä—É–ø–ø—ã –¥–ª—è –±–∏–Ω–∞—Ä–Ω–æ–≥–æ —Å–ª—É—á–∞—è (A=0, A=1)
            group_0, group_1 = unique_groups[0], unique_groups[1]

            mask_0 = protected_attr == group_0
            mask_1 = protected_attr == group_1

            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–≥–æ —Ä–∞–∑–º–µ—Ä–∞ –≥—Ä—É–ø–ø
            if np.sum(mask_0) < self.min_group_size or np.sum(mask_1) < self.min_group_size:
                return 0.0

            # P(≈∑=1|A=0) –∏ P(≈∑=1|A=1) –¥–ª—è —Ç–µ–∫—É—â–µ–≥–æ –≤—Ä–µ–º–µ–Ω–∏
            p_current_A0 = np.mean(y_pred_current[mask_0])
            p_current_A1 = np.mean(y_pred_current[mask_1])

            # P(≈∑=1|A=0) –∏ P(≈∑=1|A=1) –¥–ª—è –±–∞–∑–æ–≤–æ–≥–æ –≤—Ä–µ–º–µ–Ω–∏
            p_baseline_A0 = np.mean(y_pred_baseline[mask_0])
            p_baseline_A1 = np.mean(y_pred_baseline[mask_1])

            # üìê –§–û–†–ú–£–õ–ê TRUST-ADE
            current_disparity = abs(p_current_A0 - p_current_A1)
            baseline_disparity = abs(p_baseline_A0 - p_baseline_A1)

            dp_delta = abs(current_disparity - baseline_disparity)

            return np.clip(dp_delta, 0.0, 1.0)

        except Exception as e:
            warnings.warn(f"üö® –û—à–∏–±–∫–∞ –≤ demographic_parity_shift: {str(e)}")
            return 0.5  # —Å—Ä–µ–¥–Ω–∏–π —Ä–∏—Å–∫ –ø—Ä–∏ –æ—à–∏–±–∫–µ

    def equalized_odds_shift(self, y_true: np.ndarray,
                             y_pred_current: np.ndarray,
                             y_pred_baseline: np.ndarray,
                             protected_attr: np.ndarray) -> float:
        """
        Trust-ADE —Ñ–æ—Ä–º—É–ª–∞ —Ä–∞–≤–µ–Ω—Å—Ç–≤–∞ —à–∞–Ω—Å–æ–≤:
        EO_Œî = max_y |P(≈∑=1|A=0,y) - P(≈∑=1|A=1,y)|_t - max_y |P(≈∑=1|A=0,y) - P(≈∑=1|A=1,y)|_t-Œît

        Args:
            y_true: –∏—Å—Ç–∏–Ω–Ω—ã–µ –º–µ—Ç–∫–∏ [0/1]
            y_pred_current: —Ç–µ–∫—É—â–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è [0/1]
            y_pred_baseline: –±–∞–∑–æ–≤—ã–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è [0/1]
            protected_attr: –∑–Ω–∞—á–µ–Ω–∏—è –∑–∞—â–∏—â—ë–Ω–Ω–æ–≥–æ –∞—Ç—Ä–∏–±—É—Ç–∞

        Returns:
            float: –∏–∑–º–µ–Ω–µ–Ω–∏–µ —Ä–∞–≤–µ–Ω—Å—Ç–≤–∞ —à–∞–Ω—Å–æ–≤ [0, 1]
        """
        try:
            y_true = np.array(y_true)
            protected_attr = np.array(protected_attr)
            y_pred_current = np.array(y_pred_current)
            y_pred_baseline = np.array(y_pred_baseline)

            unique_groups = np.unique(protected_attr)
            if len(unique_groups) < 2:
                return 0.0

            group_0, group_1 = unique_groups[0], unique_groups[1]

            mask_0 = protected_attr == group_0
            mask_1 = protected_attr == group_1

            if np.sum(mask_0) < self.min_group_size or np.sum(mask_1) < self.min_group_size:
                return 0.0

            # –í—ã—á–∏—Å–ª—è–µ–º –¥–ª—è y=0 –∏ y=1 –æ—Ç–¥–µ–ª—å–Ω–æ
            current_disparities = []
            baseline_disparities = []

            for y_class in [0, 1]:
                # –ú–∞—Å–∫–∏ –¥–ª—è y=y_class –≤ –∫–∞–∂–¥–æ–π –≥—Ä—É–ø–ø–µ
                mask_0_y = mask_0 & (y_true == y_class)
                mask_1_y = mask_1 & (y_true == y_class)

                # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –µ—Å–ª–∏ –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –ø—Ä–∏–º–µ—Ä–æ–≤
                if np.sum(mask_0_y) < 5 or np.sum(mask_1_y) < 5:
                    continue

                # P(≈∑=1|A=0,y) –∏ P(≈∑=1|A=1,y) –¥–ª—è —Ç–µ–∫—É—â–µ–≥–æ –≤—Ä–µ–º–µ–Ω–∏
                p_current_A0_y = np.mean(y_pred_current[mask_0_y])
                p_current_A1_y = np.mean(y_pred_current[mask_1_y])

                # P(≈∑=1|A=0,y) –∏ P(≈∑=1|A=1,y) –¥–ª—è –±–∞–∑–æ–≤–æ–≥–æ –≤—Ä–µ–º–µ–Ω–∏
                p_baseline_A0_y = np.mean(y_pred_baseline[mask_0_y])
                p_baseline_A1_y = np.mean(y_pred_baseline[mask_1_y])

                # –†–∞–∑–ª–∏—á–∏—è –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∫–ª–∞—Å—Å–∞ y
                current_disparities.append(abs(p_current_A0_y - p_current_A1_y))
                baseline_disparities.append(abs(p_baseline_A0_y - p_baseline_A1_y))

            if len(current_disparities) == 0:
                return 0.0

            # üìê –§–û–†–ú–£–õ–ê TRUST-ADE - –º–∞–∫—Å–∏–º—É–º –ø–æ –≤—Å–µ–º y
            max_current_disparity = max(current_disparities)
            max_baseline_disparity = max(baseline_disparities)

            eo_delta = abs(max_current_disparity - max_baseline_disparity)

            return np.clip(eo_delta, 0.0, 1.0)

        except Exception as e:
            warnings.warn(f"üö® –û—à–∏–±–∫–∞ –≤ equalized_odds_shift: {str(e)}")
            return 0.5

    def calibrated_fairness_shift(self, y_true: np.ndarray,
                                  y_pred_current: np.ndarray,
                                  y_pred_baseline: np.ndarray,
                                  protected_attr: np.ndarray) -> float:
        """
        Trust-ADE —Ñ–æ—Ä–º—É–ª–∞ –∫–∞–ª–∏–±—Ä–æ–≤–∞–Ω–Ω–æ–π —Å–ø—Ä–∞–≤–µ–¥–ª–∏–≤–æ—Å—Ç–∏:
        CF_Œî = |Acc(A=0) - Acc(A=1)|_t - |Acc(A=0) - Acc(A=1)|_t-Œît

        Args:
            y_true: –∏—Å—Ç–∏–Ω–Ω—ã–µ –º–µ—Ç–∫–∏ [0/1]
            y_pred_current: —Ç–µ–∫—É—â–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è [0/1]
            y_pred_baseline: –±–∞–∑–æ–≤—ã–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è [0/1]
            protected_attr: –∑–Ω–∞—á–µ–Ω–∏—è –∑–∞—â–∏—â—ë–Ω–Ω–æ–≥–æ –∞—Ç—Ä–∏–±—É—Ç–∞

        Returns:
            float: –∏–∑–º–µ–Ω–µ–Ω–∏–µ –∫–∞–ª–∏–±—Ä–æ–≤–∞–Ω–Ω–æ–π —Å–ø—Ä–∞–≤–µ–¥–ª–∏–≤–æ—Å—Ç–∏ [0, 1]
        """
        try:
            y_true = np.array(y_true)
            protected_attr = np.array(protected_attr)
            y_pred_current = np.array(y_pred_current)
            y_pred_baseline = np.array(y_pred_baseline)

            unique_groups = np.unique(protected_attr)
            if len(unique_groups) < 2:
                return 0.0

            group_0, group_1 = unique_groups[0], unique_groups[1]

            mask_0 = protected_attr == group_0
            mask_1 = protected_attr == group_1

            if np.sum(mask_0) < self.min_group_size or np.sum(mask_1) < self.min_group_size:
                return 0.0

            # Accuracy –¥–ª—è –∫–∞–∂–¥–æ–π –≥—Ä—É–ø–ø—ã –≤ —Ç–µ–∫—É—â–µ–º –≤—Ä–µ–º–µ–Ω–∏
            try:
                acc_current_A0 = accuracy_score(y_true[mask_0], y_pred_current[mask_0])
                acc_current_A1 = accuracy_score(y_true[mask_1], y_pred_current[mask_1])

                # Accuracy –¥–ª—è –∫–∞–∂–¥–æ–π –≥—Ä—É–ø–ø—ã –≤ –±–∞–∑–æ–≤–æ–º –≤—Ä–µ–º–µ–Ω–∏
                acc_baseline_A0 = accuracy_score(y_true[mask_0], y_pred_baseline[mask_0])
                acc_baseline_A1 = accuracy_score(y_true[mask_1], y_pred_baseline[mask_1])

            except Exception as e:
                warnings.warn(f"üö® –û—à–∏–±–∫–∞ –≤ –≤—ã—á–∏—Å–ª–µ–Ω–∏–∏ accuracy: {str(e)}")
                return 0.5

            # üìê –§–û–†–ú–£–õ–ê TRUST-ADE
            current_acc_disparity = abs(acc_current_A0 - acc_current_A1)
            baseline_acc_disparity = abs(acc_baseline_A0 - acc_baseline_A1)

            cf_delta = abs(current_acc_disparity - baseline_acc_disparity)

            return np.clip(cf_delta, 0.0, 1.0)

        except Exception as e:
            warnings.warn(f"üö® –û—à–∏–±–∫–∞ –≤ calibrated_fairness_shift: {str(e)}")
            return 0.5

    def explanation_fairness_shift(self, explanations_current: Optional[np.ndarray],
                                   explanations_baseline: Optional[np.ndarray],
                                   protected_attr: np.ndarray) -> float:
        """
        –£–Ω–∏–∫–∞–ª—å–Ω–∞—è –¥–ª—è Trust-ADE –º–µ—Ç—Ä–∏–∫–∞: —Å–ø—Ä–∞–≤–µ–¥–ª–∏–≤–æ—Å—Ç—å –≤ –æ–±—ä—è—Å–Ω–µ–Ω–∏—è—Ö

        –ò–∑–º–µ—Ä—è–µ—Ç —Ä–∞–∑–ª–∏—á–∏—è –≤ –∫–∞—á–µ—Å—Ç–≤–µ –æ–±—ä—è—Å–Ω–µ–Ω–∏–π –º–µ–∂–¥—É –¥–µ–º–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏–º–∏ –≥—Ä—É–ø–ø–∞–º–∏

        Args:
            explanations_current: —Ç–µ–∫—É—â–∏–µ –æ–±—ä—è—Å–Ω–µ–Ω–∏—è [n_samples, n_features]
            explanations_baseline: –±–∞–∑–æ–≤—ã–µ –æ–±—ä—è—Å–Ω–µ–Ω–∏—è [n_samples, n_features]
            protected_attr: –∑–Ω–∞—á–µ–Ω–∏—è –∑–∞—â–∏—â—ë–Ω–Ω–æ–≥–æ –∞—Ç—Ä–∏–±—É—Ç–∞

        Returns:
            float: –∏–∑–º–µ–Ω–µ–Ω–∏–µ —Å–ø—Ä–∞–≤–µ–¥–ª–∏–≤–æ—Å—Ç–∏ –æ–±—ä—è—Å–Ω–µ–Ω–∏–π [0, 1]
        """
        try:
            if explanations_current is None or explanations_baseline is None:
                return 0.0

            explanations_current = np.array(explanations_current)
            explanations_baseline = np.array(explanations_baseline)
            protected_attr = np.array(protected_attr)

            unique_groups = np.unique(protected_attr)
            if len(unique_groups) < 2:
                return 0.0

            group_0, group_1 = unique_groups[0], unique_groups[1]

            mask_0 = protected_attr == group_0
            mask_1 = protected_attr == group_1

            if np.sum(mask_0) < self.min_group_size or np.sum(mask_1) < self.min_group_size:
                return 0.0

            # –°—Ä–µ–¥–Ω—è—è –≤–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –∫–∞–∂–¥–æ–π –≥—Ä—É–ø–ø—ã
            current_importance_A0 = np.mean(np.abs(explanations_current[mask_0]), axis=0)
            current_importance_A1 = np.mean(np.abs(explanations_current[mask_1]), axis=0)

            baseline_importance_A0 = np.mean(np.abs(explanations_baseline[mask_0]), axis=0)
            baseline_importance_A1 = np.mean(np.abs(explanations_baseline[mask_1]), axis=0)

            # –ö–æ—Å–∏–Ω—É—Å–Ω–æ–µ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –º–µ–∂–¥—É –ø–∞—Ç—Ç–µ—Ä–Ω–∞–º–∏ –æ–±—ä—è—Å–Ω–µ–Ω–∏–π –≥—Ä—É–ø–ø
            from scipy.spatial.distance import cosine

            current_explanation_disparity = cosine(current_importance_A0, current_importance_A1)
            baseline_explanation_disparity = cosine(baseline_importance_A0, baseline_importance_A1)

            # –û–±—Ä–∞–±–æ—Ç–∫–∞ NaN –∑–Ω–∞—á–µ–Ω–∏–π
            if np.isnan(current_explanation_disparity):
                current_explanation_disparity = 0.5
            if np.isnan(baseline_explanation_disparity):
                baseline_explanation_disparity = 0.5

            explanation_fairness_delta = abs(current_explanation_disparity - baseline_explanation_disparity)

            return np.clip(explanation_fairness_delta, 0.0, 1.0)

        except Exception as e:
            warnings.warn(f"üö® –û—à–∏–±–∫–∞ –≤ explanation_fairness_shift: {str(e)}")
            return 0.5

    def calculate_bias_shift_index(self, y_true: np.ndarray,
                                   y_pred_current: np.ndarray,
                                   y_pred_baseline: np.ndarray,
                                   protected_attr: np.ndarray,
                                   explanations_current: Optional[np.ndarray] = None,
                                   explanations_baseline: Optional[np.ndarray] = None) -> float:
        """
        –û—Å–Ω–æ–≤–Ω–∞—è —Ñ–æ—Ä–º—É–ª–∞ Trust-ADE –¥–ª—è Bias Shift Index:
        BS_I = ‚àö(w_dp¬∑DP_Œî¬≤ + w_eo¬∑EO_Œî¬≤ + w_cf¬∑CF_Œî¬≤)

        Args:
            y_true: –∏—Å—Ç–∏–Ω–Ω—ã–µ –º–µ—Ç–∫–∏
            y_pred_current: —Ç–µ–∫—É—â–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
            y_pred_baseline: –±–∞–∑–æ–≤—ã–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
            protected_attr: –∑–Ω–∞—á–µ–Ω–∏—è –∑–∞—â–∏—â—ë–Ω–Ω–æ–≥–æ –∞—Ç—Ä–∏–±—É—Ç–∞
            explanations_current: —Ç–µ–∫—É—â–∏–µ –æ–±—ä—è—Å–Ω–µ–Ω–∏—è (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
            explanations_baseline: –±–∞–∑–æ–≤—ã–µ –æ–±—ä—è—Å–Ω–µ–Ω–∏—è (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)

        Returns:
            float: Bias Shift Index [0, 1]
        """
        try:
            # –ö–æ–º–ø–æ–Ω–µ–Ω—Ç—ã Trust-ADE
            dp_delta = self.demographic_parity_shift(y_pred_current, y_pred_baseline, protected_attr)
            eo_delta = self.equalized_odds_shift(y_true, y_pred_current, y_pred_baseline, protected_attr)
            cf_delta = self.calibrated_fairness_shift(y_true, y_pred_current, y_pred_baseline, protected_attr)

            # üéØ –§–û–†–ú–£–õ–ê TRUST-ADE
            bs_index = np.sqrt(self.w_dp * dp_delta ** 2 +
                               self.w_eo * eo_delta ** 2 +
                               self.w_cf * cf_delta ** 2)

            return np.clip(bs_index, 0.0, 1.0)

        except Exception as e:
            warnings.warn(f"üö® –û—à–∏–±–∫–∞ –≤ calculate_bias_shift_index: {str(e)}")
            return 0.5

    def calculate(self, y_true: Union[np.ndarray, list],
                  y_pred_current: Union[np.ndarray, list],
                  y_pred_baseline: Union[np.ndarray, list],
                  protected_data: Union[np.ndarray, list],
                  explanations_current: Optional[np.ndarray] = None,
                  explanations_baseline: Optional[np.ndarray] = None,
                  verbose: bool = True) -> Dict[str, float]:
        """
        –ü–æ–ª–Ω—ã–π –∞–Ω–∞–ª–∏–∑ Bias Shift —Å–æ–≥–ª–∞—Å–Ω–æ Trust-ADE —Å –¥–µ—Ç–∞–ª—å–Ω–æ–π —Ä–∞–∑–±–∏–≤–∫–æ–π

        Args:
            y_true: –∏—Å—Ç–∏–Ω–Ω—ã–µ –º–µ—Ç–∫–∏
            y_pred_current: —Ç–µ–∫—É—â–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
            y_pred_baseline: –±–∞–∑–æ–≤—ã–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
            protected_data: –¥–∞–Ω–Ω—ã–µ –æ –∑–∞—â–∏—â—ë–Ω–Ω—ã—Ö –∞—Ç—Ä–∏–±—É—Ç–∞—Ö
            explanations_current: —Ç–µ–∫—É—â–∏–µ –æ–±—ä—è—Å–Ω–µ–Ω–∏—è (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
            explanations_baseline: –±–∞–∑–æ–≤—ã–µ –æ–±—ä—è—Å–Ω–µ–Ω–∏—è (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
            verbose: –¥–µ—Ç–∞–ª—å–Ω—ã–π –≤—ã–≤–æ–¥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤

        Returns:
            Dict[str, float]: –¥–µ—Ç–∞–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞ —Å–ø—Ä–∞–≤–µ–¥–ª–∏–≤–æ—Å—Ç–∏
        """
        try:
            if verbose:
                print(f"‚öñÔ∏è Trust-ADE Bias Shift Analysis...")

            # –í–∞–ª–∏–¥–∞—Ü–∏—è –∏ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
            y_true = np.array(y_true).flatten()
            y_pred_current = np.array(y_pred_current).flatten()
            y_pred_baseline = np.array(y_pred_baseline).flatten()

            if protected_data is None or len(protected_data) == 0:
                if verbose:
                    print("‚ö†Ô∏è  –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –æ –∑–∞—â–∏—â—ë–Ω–Ω—ã—Ö –∞—Ç—Ä–∏–±—É—Ç–∞—Ö - –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –Ω—É–ª–µ–≤–æ–µ —Å–º–µ—â–µ–Ω–∏–µ")
                return self._default_results()

            # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞—â–∏—â—ë–Ω–Ω—ã—Ö –∞—Ç—Ä–∏–±—É—Ç–æ–≤
            protected_attr = protected_data
            if isinstance(protected_data, (list, tuple)) and len(protected_data) > 0:
                protected_attr = protected_data[0]
            protected_attr = np.array(protected_attr).flatten()

            # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–µ–π
            if len(y_true) != len(y_pred_current) or len(y_true) != len(protected_attr):
                warnings.warn("üö® –ù–µ—Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–µ–π –¥–∞–Ω–Ω—ã—Ö")
                return self._default_results()

            # –ö–æ–º–ø–æ–Ω–µ–Ω—Ç—ã —Å–º–µ—â–µ–Ω–∏—è —Å–ø—Ä–∞–≤–µ–¥–ª–∏–≤–æ—Å—Ç–∏
            dp_delta = self.demographic_parity_shift(y_pred_current, y_pred_baseline, protected_attr)
            eo_delta = self.equalized_odds_shift(y_true, y_pred_current, y_pred_baseline, protected_attr)
            cf_delta = self.calibrated_fairness_shift(y_true, y_pred_current, y_pred_baseline, protected_attr)

            # –°–ø—Ä–∞–≤–µ–¥–ª–∏–≤–æ—Å—Ç—å –æ–±—ä—è—Å–Ω–µ–Ω–∏–π (—É–Ω–∏–∫–∞–ª—å–Ω–æ –¥–ª—è Trust-ADE)
            explanation_fairness_delta = 0.0
            if explanations_current is not None and explanations_baseline is not None:
                explanation_fairness_delta = self.explanation_fairness_shift(
                    explanations_current, explanations_baseline, protected_attr
                )

            # üéØ –û—Å–Ω–æ–≤–Ω–∞—è —Ñ–æ—Ä–º—É–ª–∞ Trust-ADE
            bias_shift_index = np.sqrt(self.w_dp * dp_delta ** 2 +
                                       self.w_eo * eo_delta ** 2 +
                                       self.w_cf * cf_delta ** 2)

            # –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è —É—Ä–æ–≤–Ω—è —Å–º–µ—â–µ–Ω–∏—è
            if bias_shift_index < 0.1:
                bias_level = "Minimal"
            elif bias_shift_index < 0.3:
                bias_level = "Low"
            elif bias_shift_index < 0.5:
                bias_level = "Moderate"
            elif bias_shift_index < 0.7:
                bias_level = "High"
            else:
                bias_level = "Critical"

            results = {
                'bias_shift_index': np.clip(bias_shift_index, 0.0, 1.0),
                'demographic_parity_shift': np.clip(dp_delta, 0.0, 1.0),
                'equality_of_odds_shift': np.clip(eo_delta, 0.0, 1.0),
                'calibrated_fairness_shift': np.clip(cf_delta, 0.0, 1.0),
                'explanation_fairness_shift': np.clip(explanation_fairness_delta, 0.0, 1.0),
                'bias_level': bias_level,
                'protected_groups': len(np.unique(protected_attr)),
                'weights': {
                    'w_dp': self.w_dp,
                    'w_eo': self.w_eo,
                    'w_cf': self.w_cf
                }
            }

            if verbose:
                print(f"üìä Trust-ADE Bias Shift Results:")
                print(f"   üéØ Bias Shift Index: {results['bias_shift_index']:.4f} ({bias_level})")
                print(f"   üìä Demographic Parity Œî: {results['demographic_parity_shift']:.4f}")
                print(f"   ‚öñÔ∏è Equalized Odds Œî: {results['equality_of_odds_shift']:.4f}")
                print(f"   üìà Calibrated Fairness Œî: {results['calibrated_fairness_shift']:.4f}")
                print(f"   üß† Explanation Fairness Œî: {results['explanation_fairness_shift']:.4f}")
                print(f"   üë• Protected Groups: {results['protected_groups']}")

            return results

        except Exception as e:
            warnings.warn(f"üö® –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –≤ BiasShiftIndex.calculate: {str(e)}")
            return self._default_results()

    def _default_results(self) -> Dict[str, float]:
        """–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –ø—Ä–∏ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö –æ—à–∏–±–∫–∞—Ö"""
        return {
            'bias_shift_index': 0.0,
            'demographic_parity_shift': 0.0,
            'equality_of_odds_shift': 0.0,
            'calibrated_fairness_shift': 0.0,
            'explanation_fairness_shift': 0.0,
            'bias_level': 'Unknown',
            'protected_groups': 0,
            'weights': {
                'w_dp': self.w_dp,
                'w_eo': self.w_eo,
                'w_cf': self.w_cf
            }
        }