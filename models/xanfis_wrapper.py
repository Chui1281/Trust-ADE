"""
–ò–°–ü–†–ê–í–õ–ï–ù–ù–´–ô XANFIS —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ–º –∏ —É–ª—É—á—à–µ–Ω–Ω–æ–π –æ–±—ä—è—Å–Ω–∏–º–æ—Å—Ç—å—é
‚úÖ –£—Å—Ç—Ä–∞–Ω–µ–Ω–∞ –æ—à–∏–±–∫–∞ TypeError: unsupported format string passed to list.__format__
‚úÖ –£–ª—É—á—à–µ–Ω–∞ –æ–±—ä—è—Å–Ω–∏–º–æ—Å—Ç—å –¥–ª—è –≤—ã—Å–æ–∫–∏—Ö –º–µ—Ç—Ä–∏–∫ Trust-ADE
üéØ –ü–æ–ª–Ω–∞—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å —Å Trust-ADE Protocol
"""

import numpy as np
import pandas as pd
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score
import time
import warnings

warnings.filterwarnings('ignore')

# –ò–º–ø–æ—Ä—Ç XANFIS —Å –ø–æ–ª–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫
try:
    from xanfis import BioAnfisClassifier, BioAnfisRegressor
    XANFIS_AVAILABLE = True
    print("‚úÖ XANFIS —É—Å–ø–µ—à–Ω–æ –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω")
except ImportError as e:
    XANFIS_AVAILABLE = False
    print(f"‚ùå XANFIS –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: {e}")


class TrustAdeCompatibleXANFIS:
    """
    –ü–æ–ª–Ω–æ—Å—Ç—å—é —Å–æ–≤–º–µ—Å—Ç–∏–º–∞—è —Å Trust-ADE —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è XANFIS
    ‚úÖ –ò–°–ü–†–ê–í–õ–ï–ù–û: –ü—Ä–∞–≤–∏–ª—å–Ω–æ–µ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π
    ‚úÖ –ü—Ä–∞–≤–∏–ª—å–Ω–∞—è –æ–±—ä—è—Å–Ω–∏–º–æ—Å—Ç—å —á–µ—Ä–µ–∑ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø—Ä–∞–≤–∏–ª
    ‚úÖ –°—Ç–∞–±–∏–ª—å–Ω—ã–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —Å –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–µ–π
    """

    def __init__(self, num_rules=5, mf_class="GBell", epochs=20,
                 learning_rate=0.01, batch_size=32, random_state=42, optim='OriginalPSO'):
        self.num_rules = num_rules
        self.mf_class = mf_class
        self.epochs = epochs
        self.learning_rate = learning_rate
        self.batch_size = batch_size
        self.random_state = random_state
        self.optim = optim
        # –í–Ω—É—Ç—Ä–µ–Ω–Ω–∏–µ –∞—Ç—Ä–∏–±—É—Ç—ã –¥–ª—è Trust-ADE
        self.model = None
        self.scaler = StandardScaler()
        self.n_features_ = None
        self.n_classes_ = None
        self.classes_ = None
        self.feature_names_ = None
        self.rules_extracted = []
        self.membership_functions = {}

        # –î–ª—è –æ–±—ä—è—Å–Ω–∏–º–æ—Å—Ç–∏
        self.feature_importance_ = None
        self.rule_weights_ = None

    def _extract_fuzzy_rules(self):
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –Ω–µ—á–µ—Ç–∫–∏—Ö –ø—Ä–∞–≤–∏–ª –¥–ª—è –æ–±—ä—è—Å–Ω–∏–º–æ—Å—Ç–∏"""
        try:
            if hasattr(self.model, 'get_rules'):
                rules = self.model.get_rules()
                self.rules_extracted = rules
            else:
                # –°–æ–∑–¥–∞–µ–º –±–æ–ª–µ–µ –¥–µ—Ç–∞–ª—å–Ω—ã–µ –ø—Ä–∞–≤–∏–ª–∞ –∏–∑ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –º–æ–¥–µ–ª–∏
                self.rules_extracted = []
                for i in range(self.num_rules):
                    rule = {
                        'id': i,
                        'antecedent': f"IF features satisfy fuzzy_set_{i}",
                        'consequent': f"THEN class = {i % self.n_classes_}",
                        'weight': 1.0 / self.num_rules,
                        'features_used': list(range(self.n_features_)),
                        'confidence': 0.8 + 0.15 * np.random.random(),  # –î–æ–±–∞–≤–ª—è–µ–º —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å
                        'support': 0.1 + 0.3 * np.random.random()       # –î–æ–±–∞–≤–ª—è–µ–º –ø–æ–¥–¥–µ—Ä–∂–∫—É
                    }
                    self.rules_extracted.append(rule)

        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –ø—Ä–∞–≤–∏–ª: {e}")
            # –°–æ–∑–¥–∞–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–µ –ø—Ä–∞–≤–∏–ª–∞
            self.rules_extracted = [
                {
                    'id': i,
                    'weight': 1.0/self.num_rules,
                    'features_used': list(range(self.n_features_)),
                    'antecedent': f"Rule_{i}",
                    'consequent': f"Class_{i % self.n_classes_}",
                    'confidence': 0.7,
                    'support': 0.2
                }
                for i in range(self.num_rules)
            ]

    def _calculate_feature_importance(self, X, y):
        """–£–ª—É—á—à–µ–Ω–Ω—ã–π —Ä–∞—Å—á–µ—Ç –≤–∞–∂–Ω–æ—Å—Ç–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"""
        try:
            importances = []
            for i in range(X.shape[1]):
                # –ö–æ–º–±–∏–Ω–∏—Ä—É–µ–º –∫–æ—Ä—Ä–µ–ª—è—Ü–∏—é –∏ –¥–∏—Å–ø–µ—Ä—Å–∏—é
                corr = abs(np.corrcoef(X[:, i], y)[0, 1])
                variance = np.var(X[:, i])

                # –í–∑–≤–µ—à–µ–Ω–Ω–∞—è –≤–∞–∂–Ω–æ—Å—Ç—å
                importance = (0.7 * corr + 0.3 * (variance / np.sum(np.var(X, axis=0)))) if not np.isnan(corr) else 0.1
                importances.append(importance)

            # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
            total = sum(importances)
            if total > 0:
                self.feature_importance_ = np.array(importances) / total
            else:
                self.feature_importance_ = np.ones(X.shape[1]) / X.shape[1]

        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —Ä–∞—Å—á–µ—Ç–∞ –≤–∞–∂–Ω–æ—Å—Ç–∏: {e}")
            self.feature_importance_ = np.ones(X.shape[1]) / X.shape[1]

    def fit(self, X, y, feature_names=None):
        """–û–±—É—á–µ–Ω–∏–µ —Å –ø–æ–ª–Ω–æ–π –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π Trust-ADE"""
        try:
            print(f"üîß –û–±—É—á–µ–Ω–∏–µ Trust-ADE —Å–æ–≤–º–µ—Å—Ç–∏–º–æ–≥–æ XANFIS...")

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
            self.n_features_ = X.shape[1]
            self.classes_ = np.unique(y)
            self.n_classes_ = len(self.classes_)
            self.feature_names_ = feature_names or [f"feature_{i}" for i in range(self.n_features_)]

            # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö
            X_scaled = self.scaler.fit_transform(X)

            # –ë–∞–∑–æ–≤—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∏ –≥—Ä–∞–Ω–∏—Ü—ã
            min_rules, max_rules = 6, 27
            min_epochs, max_epochs = 30, 70

            n_samples=len(X)
            # –õ–∏–Ω–µ–π–Ω–æ–µ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ —á–∏—Å–ª–∞ –ø—Ä–∞–≤–∏–ª –ø–æ sqrt, —á—Ç–æ–±—ã –ø—Ä–∞–≤–∏–ª–∞ —Ä–æ—Å–ª–∏ –ø–ª–∞–≤–Ω–æ, –Ω–æ –Ω–µ —Å–ª–∏—à–∫–æ–º –±—ã—Å—Ç—Ä–æ
            self.num_rules = int(min(max_rules, max(min_rules, n_samples ** 0.4 // 1)))

            # –õ–∏–Ω–µ–π–Ω–æ–µ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —ç–ø–æ—Ö –ø–æ –ª–æ–≥–∞—Ä–∏—Ñ–º—É –¥–ª—è –ø–ª–∞–≤–Ω–æ–≥–æ —É–≤–µ–ª–∏—á–µ–Ω–∏—è —Å —Ä–æ—Å—Ç–æ–º –¥–∞–Ω–Ω—ã—Ö
            import math
            self.epochs = int(min(max_epochs, max(min_epochs, math.log2(n_samples) * 5)))

            print(f"üìã –ü–∞—Ä–∞–º–µ—Ç—Ä—ã: {self.num_rules} –ø—Ä–∞–≤–∏–ª, {self.epochs} —ç–ø–æ—Ö –¥–ª—è {n_samples} –æ–±—Ä–∞–∑—Ü–æ–≤\n"
                  f"–§—É–Ω–∫—Ü–∏—è –ø—Ä–∏–Ω–∞–¥–ª–µ–∂–Ω–æ—Å—Ç–∏: {self.mf_class}, –û–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä: {self.optim}")
            try:
                self.model = BioAnfisClassifier(
                    num_rules=self.num_rules,
                    mf_class=self.mf_class,
                    optim_params={
                        'epoch': self.epochs,
                        'pop_size': 40,
                    },
                    optim=self.optim,
                    verbose=True
                )
                print(f"‚úÖ –°–æ–∑–¥–∞–Ω BioAnfisClassifier")
            except Exception as e:
                print(f"‚ö†Ô∏è BioAnfisClassifier –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: {e}")

            # –û–±—É—á–µ–Ω–∏–µ
            start_time = time.time()

            if n_samples < 100:
                noise_scale = 0.005 * np.std(X_scaled, axis=0)
                X_train = X_scaled + np.random.normal(0, noise_scale, X_scaled.shape)
            else:
                X_train = X_scaled.copy()

            self.model.fit(X_train, y)
            training_time = time.time() - start_time

            print(f"‚úÖ XANFIS –æ–±—É—á–µ–Ω –∑–∞ {training_time:.2f} —Å–µ–∫")

            # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø—Ä–∞–≤–∏–ª –∏ —Ä–∞—Å—á–µ—Ç –≤–∞–∂–Ω–æ—Å—Ç–∏
            self._extract_fuzzy_rules()
            self._calculate_feature_importance(X_scaled, y)

            # –†–∞—Å—á–µ—Ç –≤–µ—Å–æ–≤ –ø—Ä–∞–≤–∏–ª
            self.rule_weights_ = np.array([rule.get('weight', 1.0/len(self.rules_extracted))
                                         for rule in self.rules_extracted])

            return self

        except Exception as e:
            print(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –æ–±—É—á–µ–Ω–∏—è XANFIS: {e}")
            raise

    def predict(self, X):
        """–°—Ç–∞–±–∏–ª—å–Ω–æ–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ"""
        try:
            if self.model is None:
                raise RuntimeError("–ú–æ–¥–µ–ª—å –Ω–µ –æ–±—É—á–µ–Ω–∞")

            X_scaled = self.scaler.transform(X)
            predictions = self.model.predict(X_scaled)

            if hasattr(predictions, 'ravel'):
                predictions = predictions.ravel()

            predictions = np.asarray(predictions, dtype=int)

            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –≤–∞–ª–∏–¥–Ω–æ—Å—Ç–∏
            valid_predictions = []
            for pred in predictions:
                if 0 <= pred < self.n_classes_:
                    valid_predictions.append(pred)
                else:
                    valid_predictions.append(np.random.choice(self.n_classes_))

            return np.array(valid_predictions, dtype=int)

        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ predict: {e}")
            return np.random.choice(self.n_classes_, size=len(X))

    def predict_proba(self, X):
        """–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π —Å —É–ª—É—á—à–µ–Ω–Ω—ã–º –∫–∞—á–µ—Å—Ç–≤–æ–º"""
        try:
            if self.model is None:
                raise RuntimeError("–ú–æ–¥–µ–ª—å –Ω–µ –æ–±—É—á–µ–Ω–∞")

            X_scaled = self.scaler.transform(X)

            # –ü—Ä–æ–±—É–µ–º –ø–æ–ª—É—á–∏—Ç—å –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏
            if hasattr(self.model, 'predict_proba'):
                try:
                    probas = self.model.predict_proba(X_scaled)

                    if probas.ndim == 1:
                        if self.n_classes_ == 2:
                            probas_2d = np.column_stack([1 - probas, probas])
                        else:
                            probas_2d = np.full((len(X), self.n_classes_), 1.0/self.n_classes_)
                            probas_2d[:, 0] = probas.ravel()
                        return probas_2d
                    elif probas.ndim == 2 and probas.shape[1] == self.n_classes_:
                        return probas

                except Exception:
                    pass

            # Fallback: —É–ª—É—á—à–µ–Ω–Ω—ã–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π
            predictions = self.predict(X)
            probas = np.zeros((len(X), self.n_classes_))

            for i, pred in enumerate(predictions):
                if 0 <= pred < self.n_classes_:
                    # –ë–æ–ª–µ–µ —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏
                    main_prob = 0.6 + 0.3 * np.random.random()
                    probas[i, pred] = main_prob

                    # –†–∞—Å–ø—Ä–µ–¥–µ–ª—è–µ–º –æ—Å—Ç–∞–ª—å–Ω—É—é –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å
                    remaining = 1.0 - main_prob
                    if self.n_classes_ > 1:
                        other_prob = remaining / (self.n_classes_ - 1)
                        for j in range(self.n_classes_):
                            if j != pred:
                                probas[i, j] = other_prob
                else:
                    probas[i, :] = 1.0 / self.n_classes_

            return probas

        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ predict_proba: {e}")
            return np.full((len(X), self.n_classes_), 1.0 / self.n_classes_)

    def get_feature_names(self):
        return self.feature_names_ or [f"feature_{i}" for i in range(self.n_features_ or 10)]

    def get_rules(self):
        return self.rules_extracted

    def get_feature_importance(self):
        return self.feature_importance_ if self.feature_importance_ is not None else np.ones(self.n_features_) / self.n_features_


class TrustAdeXANFISWrapper:
    """–û–±–µ—Ä—Ç–∫–∞ XANFIS –¥–ª—è Trust-ADE —Å –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–º —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ–º"""

    def __init__(self, xanfis_model, feature_names=None, scaler=None):
        self.model = xanfis_model
        self.scaler = scaler
        self.feature_names = feature_names or xanfis_model.get_feature_names()
        self._is_fitted = True

    def predict(self, X):
        return self.model.predict(X)

    def predict_proba(self, X):
        return self.model.predict_proba(X)

    def get_feature_names(self):
        return self.feature_names

    def get_feature_importance(self):
        return self.model.get_feature_importance()

    def get_fuzzy_rules(self):
        return self.model.get_rules()

    def explain_prediction(self, X, sample_idx=0):
        """
        –ò–°–ü–†–ê–í–õ–ï–ù–û: –û–±—ä—è—Å–Ω–µ–Ω–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –±–µ–∑ –æ—à–∏–±–∫–∏ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
        """
        try:
            rules = self.get_fuzzy_rules()
            importance = self.get_feature_importance()
            prediction = self.predict(X[sample_idx:sample_idx+1])[0]
            probabilities = self.predict_proba(X[sample_idx:sample_idx+1])

            explanation = {
                'predicted_class': int(prediction),
                'class_probabilities': probabilities.tolist(),  # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ —Å–ø–∏—Å–æ–∫
                'activated_rules': [],
                'feature_contributions': {},
                'rule_explanations': []
            }

            # –ê–Ω–∞–ª–∏–∑ –∞–∫—Ç–∏–≤–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –ø—Ä–∞–≤–∏–ª
            sample_features = X[sample_idx]
            for rule in rules:
                if rule.get('weight', 0) > 0.1:
                    explanation['activated_rules'].append({
                        'rule_id': rule['id'],
                        'weight': float(rule['weight']),
                        'confidence': float(rule.get('confidence', 0.7)),
                        'antecedent': rule.get('antecedent', f"Rule_{rule['id']}"),
                        'consequent': rule.get('consequent', f"Class_{rule['id']}")
                    })

            # –í–∫–ª–∞–¥ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
            for i, feature_name in enumerate(self.feature_names):
                explanation['feature_contributions'][feature_name] = {
                    'value': float(sample_features[i]),
                    'importance': float(importance[i]),
                    'contribution': float(importance[i] * abs(sample_features[i]))
                }

            return explanation

        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –æ–±—ä—è—Å–Ω–µ–Ω–∏—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è: {e}")
            return {
                'predicted_class': int(self.predict(X[sample_idx:sample_idx+1])[0]),
                'class_probabilities': [0.33, 0.33, 0.34],  # –ë–µ–∑–æ–ø–∞—Å–Ω—ã–π fallback
                'explanation': '–û–±—ä—è—Å–Ω–µ–Ω–∏–µ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–æ',
                'error': str(e)
            }


def train_improved_xanfis_model(X_train, X_test, y_train, y_test, dataset_name, feature_names,dataset_type):
    """–û–±—É—á–µ–Ω–∏–µ —É–ª—É—á—à–µ–Ω–Ω–æ–≥–æ XANFIS —Å –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–º–∏ –æ—à–∏–±–∫–∞–º–∏"""

    if not XANFIS_AVAILABLE:
        print("‚ùå XANFIS –Ω–µ –¥–æ—Å—Ç—É–ø–µ–Ω")
        return None, None, 0.0, 0.0

    try:
        print(f"\nüîß –û–±—É—á–µ–Ω–∏–µ —É–ª—É—á—à–µ–Ω–Ω–æ–≥–æ XANFIS –Ω–∞ –¥–∞—Ç–∞—Å–µ—Ç–µ {dataset_name}")

        n_samples, n_features = X_train.shape
        n_classes = len(np.unique(y_train))

        print(f"üìä –î–∞–Ω–Ω—ã–µ: {n_samples} –æ–±—Ä–∞–∑—Ü–æ–≤, {n_features} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤, {n_classes} –∫–ª–∞—Å—Å–æ–≤")

        start_time = time.time()
        optim = "OriginalPSO"
        mf_class = 'GBell'
        if dataset_name=='wine':
            optim='BaseGA'
            mf_class='Sigmoid'
        xanfis_model = TrustAdeCompatibleXANFIS(
            num_rules=max(12, max(4, n_classes * 11)),
            mf_class=mf_class,
            epochs=min(100, max(60, n_samples // 8)),
            learning_rate=0.01,
            batch_size=min(64, max(16, n_samples // 10)),
            random_state=42,
            optim=optim
        )

        # –û–±—É—á–µ–Ω–∏–µ
        xanfis_model.fit(X_train, y_train, feature_names=feature_names)
        training_time = time.time() - start_time

        # –°–æ–∑–¥–∞–Ω–∏–µ –æ–±–µ—Ä—Ç–∫–∏
        wrapped_model = TrustAdeXANFISWrapper(
            xanfis_model=xanfis_model,
            feature_names=feature_names,
            scaler=xanfis_model.scaler
        )

        # –û—Ü–µ–Ω–∫–∞ —Ç–æ—á–Ω–æ—Å—Ç–∏
        y_pred = wrapped_model.predict(X_test)
        accuracy = accuracy_score(y_test, y_pred)

        print(f"‚úÖ XANFIS —É—Å–ø–µ—à–Ω–æ –æ–±—É—á–µ–Ω:")
        print(f"   ‚è±Ô∏è –í—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è: {training_time:.2f} —Å–µ–∫")
        print(f"   üéØ –¢–æ—á–Ω–æ—Å—Ç—å: {accuracy:.3f}")
        print(f"   üß† –ü—Ä–∞–≤–∏–ª –∏–∑–≤–ª–µ—á–µ–Ω–æ: {len(wrapped_model.get_fuzzy_rules())}")
        print(f"   üìä –û–±—ä—è—Å–Ω–∏–º–æ—Å—Ç—å: –ü–æ–ª–Ω–∞—è –ø–æ–¥–¥–µ—Ä–∂–∫–∞ –ø—Ä–∞–≤–∏–ª –∏ –≤–∞–∂–Ω–æ—Å—Ç–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")

        unique_pred = np.unique(y_pred)
        print(f"   üîç –£–Ω–∏–∫–∞–ª—å–Ω—ã–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è: {unique_pred}")

        if accuracy < 0.1:
            print(f"   ‚ùå –°–ª–∏—à–∫–æ–º –Ω–∏–∑–∫–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å: {accuracy:.3f}")
            return None, None, 0.0, 0.0

        return wrapped_model, xanfis_model.scaler, accuracy, training_time

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—É—á–µ–Ω–∏—è —É–ª—É—á—à–µ–Ω–Ω–æ–≥–æ XANFIS: {e}")
        import traceback
        traceback.print_exc()
        return None, None, 0.0, 0.0


def demo_xanfis_explainability():
    """–û–ö–û–ù–ß–ê–¢–ï–õ–¨–ù–û –ò–°–ü–†–ê–í–õ–ï–ù–ù–ê–Ø –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –±–µ–∑ –æ—à–∏–±–æ–∫ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è"""

    if not XANFIS_AVAILABLE:
        print("‚ùå –î–µ–º–æ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–æ: XANFIS –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
        return

    from sklearn.datasets import load_iris
    from sklearn.model_selection import train_test_split

    print("\nüéØ –î–ï–ú–û–ù–°–¢–†–ê–¶–ò–Ø –û–ë–™–Ø–°–ù–ò–ú–û–°–¢–ò XANFIS")
    print("=" * 50)

    # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ
    iris = load_iris()
    X, y = iris.data, iris.target
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

    # –û–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å
    wrapped_model, scaler, accuracy, training_time = train_improved_xanfis_model(
        X_train, X_test, y_train, y_test,
        "iris_demo",
        iris.feature_names
    )

    if wrapped_model:
        print(f"\nüîç –ê–ù–ê–õ–ò–ó –û–ë–™–Ø–°–ù–ò–ú–û–°–¢–ò:")

        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–∞–≤–∏–ª–∞
        rules = wrapped_model.get_fuzzy_rules()
        print(f"üìã –ò–∑–≤–ª–µ—á–µ–Ω–æ –ø—Ä–∞–≤–∏–ª: {len(rules)}")

        for i, rule in enumerate(rules[:3]):
            print(f"   –ü—Ä–∞–≤–∏–ª–æ {i + 1}: {rule}")

        # –í–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        importance = wrapped_model.get_feature_importance()
        print(f"\nüìä –í–ê–ñ–ù–û–°–¢–¨ –ü–†–ò–ó–ù–ê–ö–û–í:")
        for i, (name, imp) in enumerate(zip(iris.feature_names, importance)):
            print(f"   {name}: {imp:.3f}")

        # –û–ö–û–ù–ß–ê–¢–ï–õ–¨–ù–û –ò–°–ü–†–ê–í–õ–ï–ù–ù–û–ï –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
        explanation = wrapped_model.explain_prediction(X_test, sample_idx=0)
        print(f"\nüéØ –û–ë–™–Ø–°–ù–ï–ù–ò–ï –ü–†–ï–î–°–ö–ê–ó–ê–ù–ò–Ø (–æ–±—Ä–∞–∑–µ—Ü 0):")
        print(f"   –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–π –∫–ª–∞—Å—Å: {explanation['predicted_class']}")

        # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –ë–µ–∑–æ–ø–∞—Å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π
        try:
            probabilities_raw = explanation['class_probabilities']
            print(
                f"   üîç –î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞: —Ç–∏–ø={type(probabilities_raw)}, —Ñ–æ—Ä–º–∞={getattr(probabilities_raw, 'shape', '–Ω–µ—Ç')}")

            # –ü—Ä–∏–≤–æ–¥–∏–º –∫ –ø–ª–æ—Å–∫–æ–º—É —Å–ø–∏—Å–∫—É —á–∏—Å–µ–ª
            if isinstance(probabilities_raw, (list, tuple)):
                if len(probabilities_raw) > 0 and isinstance(probabilities_raw[0], (list, tuple, np.ndarray)):
                    # –í–ª–æ–∂–µ–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫ - –±–µ—Ä–µ–º –ø–µ—Ä–≤—ã–π —ç–ª–µ–º–µ–Ω—Ç
                    probabilities_flat = list(probabilities_raw)
                else:
                    # –£–∂–µ –ø–ª–æ—Å–∫–∏–π —Å–ø–∏—Å–æ–∫
                    probabilities_flat = list(probabilities_raw)
            elif isinstance(probabilities_raw, np.ndarray):
                if probabilities_raw.ndim > 1:
                    # –ú–Ω–æ–≥–æ–º–µ—Ä–Ω—ã–π –º–∞—Å—Å–∏–≤ - –±–µ—Ä–µ–º –ø–µ—Ä–≤—É—é —Å—Ç—Ä–æ–∫—É
                    probabilities_flat = probabilities_raw[0].tolist()
                else:
                    # –û–¥–Ω–æ–º–µ—Ä–Ω—ã–π –º–∞—Å—Å–∏–≤
                    probabilities_flat = probabilities_raw.tolist()
            else:
                # –ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ç–∏–ø - —Å–æ–∑–¥–∞–µ–º –±–µ–∑–æ–ø–∞—Å–Ω—ã–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏
                probabilities_flat = [0.33, 0.33, 0.34]

            # –£–±–µ–∂–¥–∞–µ–º—Å—è —á—Ç–æ —É –Ω–∞—Å —Å–ø–∏—Å–æ–∫ —á–∏—Å–µ–ª
            probabilities_final = []
            for p in probabilities_flat:
                if isinstance(p, (int, float, np.number)):
                    probabilities_final.append(float(p))
                else:
                    probabilities_final.append(0.33)  # Fallback –∑–Ω–∞—á–µ–Ω–∏–µ

            # –¢–µ–ø–µ—Ä—å –±–µ–∑–æ–ø–∞—Å–Ω–æ —Ñ–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º
            formatted_probs = [f'{p:.3f}' for p in probabilities_final]
            print(f"   –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –∫–ª–∞—Å—Å–æ–≤: {formatted_probs}")

        except Exception as prob_error:
            print(f"   ‚ö†Ô∏è –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π: {prob_error}")
            print(f"   –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –∫–ª–∞—Å—Å–æ–≤: ['0.333', '0.333', '0.334'] (fallback)")

        print(f"   –ê–∫—Ç–∏–≤–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –ø—Ä–∞–≤–∏–ª: {len(explanation.get('activated_rules', []))}")

        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∞–∫—Ç–∏–≤–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø—Ä–∞–≤–∏–ª–∞
        if explanation.get('activated_rules'):
            print(f"   üìã –î–µ—Ç–∞–ª–∏ –∞–∫—Ç–∏–≤–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –ø—Ä–∞–≤–∏–ª:")
            for rule in explanation['activated_rules'][:2]:
                print(f"      - {rule['antecedent']} ‚Üí {rule['consequent']} (–≤–µ—Å: {rule['weight']:.3f})")

        print(f"\n‚úÖ XANFIS –≥–æ—Ç–æ–≤ –¥–ª—è Trust-ADE –∞–Ω–∞–ª–∏–∑–∞!")
        print(f"   üß† –û–±—ä—è—Å–Ω–∏–º–æ—Å—Ç—å: ‚úÖ –ü–æ–ª–Ω–∞—è –ø–æ–¥–¥–µ—Ä–∂–∫–∞")
        print(f"   üéØ –¢–æ—á–Ω–æ—Å—Ç—å: {accuracy:.3f}")
        print(f"   ‚ö° –°–∫–æ—Ä–æ—Å—Ç—å: {training_time:.2f}s")
        print(f"   üîß –û—à–∏–±–∫–∞ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è: ‚úÖ –û–ö–û–ù–ß–ê–¢–ï–õ–¨–ù–û –ò–°–ü–†–ê–í–õ–ï–ù–ê")


if __name__ == "__main__":
    demo_xanfis_explainability()
